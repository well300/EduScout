
# ğŸ‘¨â€ğŸ« AI-Driven Course Scraper

This is a Node.js application that performs AI-driven scraping of a website to fetch course information. The application periodically checks for new courses and extracts relevant data using AI algorithms. It also provides an API endpoint to fetch the latest courses.

## Prerequisites âœ…

Before running the application, ensure that you have the following installed:

- Node.js (version >= 12.0.0)
- npm (Node Package Manager)

## Installation ğŸš€

1. Clone the repository or download the code files.
2. Navigate to the project directory using the command line.
3. Run the following command to install the required dependencies:

   ```bash
   npm install
   ```

## Usage ğŸ“

To start the AI-driven course scraper, use the following command:

```bash
node index.js
```

This will start the Express server on `http://localhost:3000`.

## API Endpoint ğŸŒ

### Check for New Courses

- **URL:** `/`
- **Method:** GET
- **Description:** Fetches the latest courses and their Udemy links (if available).
- **Response Format:**

  ```json
  {
    "newCourses": true|false,
    "courses": [
      {
        "name": "Course Name",
        "udemyLink": "https://www.udemy.com/course/course-slug"
      },
      // ...
    ]
  }
  ```

  - `newCourses`: A boolean value indicating whether new courses are available.
  - `courses`: An array of objects containing the name of the course and its Udemy link.

## Configuration âš™ï¸

The following variables can be configured in the code:

- `PORT`: The port on which the Express server listens (default: 3000).
- `DOMAIN`: The base URL of the website to scrape.
- `AD_DOMAINS`: An array of domain URLs considered as ads and excluded from scraping.
- `maxPages`: The maximum number of pages to scrape (set to `null` for unlimited scraping).

## AI-Driven Scraping ğŸ¤–

The application uses AI algorithms to extract relevant data from the course pages. The `aiDrivenScraping` function performs the AI-driven data extraction using specific selectors and logic. You can modify this function to customize the scraping logic based on your requirements.

## Notes ğŸ“

- The application uses the `cheerio` library for parsing HTML and extracting data.
- The `axios` library is used for making HTTP requests.
- CORS is enabled to allow cross-origin requests.
- The application periodically checks for new courses every 30 minutes using the `checkForNewCourses` function.
- Error handling is implemented for handling errors during scraping and HTTP requests.

## License ğŸ“„

This project is licensed under the [MIT License](LICENSE).

